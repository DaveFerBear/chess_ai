{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.pgn\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_SPACES = 64\n",
    "ROWS = 8\n",
    "COLS = 8\n",
    "\n",
    "letter_lookup = {\n",
    "    'a':0,\n",
    "    'b':1,\n",
    "    'c':2,\n",
    "    'd':3,\n",
    "    'e':4,\n",
    "    'f':5,\n",
    "    'g':6,\n",
    "    'h':7\n",
    "}\n",
    "piece_lookup = {\n",
    "    'r':1,\n",
    "    'n':2,\n",
    "    'b':3,\n",
    "    'q':4,\n",
    "    'k':5,\n",
    "    'p':6,\n",
    "    'R':-1,\n",
    "    'N':-2,\n",
    "    'B':-3,\n",
    "    'Q':-4,\n",
    "    'K':-5,\n",
    "    'P':-6,\n",
    "    '.':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [-1.,  0.,  0.,  0.,  0.,  0.,  0., -1.]],\n",
       "\n",
       "       [[ 0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0., -1.,  0.,  0.,  0.,  0., -1.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0., -1.,  0.,  0., -1.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format of Dataset\n",
    "# One chanel per piece\n",
    "# One additional channel showing whose turn it is\n",
    "# Referenced from https://int8.io/chess-position-evaluation-with-convolutional-neural-networks-in-julia/\n",
    "\n",
    "dataset_x = []\n",
    "dataset_y = []\n",
    "posns = []\n",
    "\n",
    "pgn = open(\"datasets/AllGames.pgn\")\n",
    "game = chess.pgn.read_game(pgn)\n",
    "board = game.board()\n",
    "black_or_white = True\n",
    "count = 0\n",
    "\n",
    "while game != None:\n",
    "#     print(count)\n",
    "    count += 1\n",
    "    if count >= 2000:\n",
    "        break\n",
    "\n",
    "    for move in game.mainline_moves():\n",
    "        dp = []\n",
    "        \n",
    "        # Create a one-hot label for the move\n",
    "        label = np.zeros(BOARD_SPACES*2)\n",
    "        pos1 = str(move)[:2]\n",
    "        pos1 = ROWS*letter_lookup[pos1[0]] + int(pos1[1])-1\n",
    "        label[pos1] = 1\n",
    "        pos2 = str(move)[2:]\n",
    "        pos2 = ROWS*letter_lookup[pos2[0]] + int(pos2[1])-1\n",
    "        label[(BOARD_SPACES) + pos2] = 1\n",
    "        \n",
    "        posns.append((pos1, pos2))\n",
    "        \n",
    "        # Turn the board into a vector\n",
    "        strboard = str(board)\n",
    "        board_data = np.zeros((7, 8, 8))\n",
    "        idx = 0\n",
    "        for char in strboard:\n",
    "            if char in piece_lookup:\n",
    "                if char != '.':\n",
    "                    board_data[abs(piece_lookup[char])-1][int(idx/COLS)][idx%ROWS] \\\n",
    "                        = piece_lookup[char]/abs(piece_lookup[char])\n",
    "                idx += 1\n",
    "        # Fill the final channel with ones if white\n",
    "        if black_or_white == True:\n",
    "            board_data[6].fill(1)\n",
    "                \n",
    "        dataset_x.append(board_data)\n",
    "        dataset_y.append(label)  \n",
    "        black_or_white = not black_or_white\n",
    "        board.push(move)\n",
    "    game = chess.pgn.read_game(pgn)\n",
    "\n",
    "dataset_x = np.stack(dataset_x)\n",
    "dataset_y = np.stack(dataset_y)\n",
    "dataset_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170087, 7, 8, 8) 128\n"
     ]
    }
   ],
   "source": [
    "inshape = dataset_x[0].shape\n",
    "outshape = dataset_y[0].size\n",
    "print(dataset_x.shape, outshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(400, kernel_size=(4, 4),\n",
    "                 activation='relu',\n",
    "                 input_shape=inshape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(200, kernel_size=(2, 2),\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(outshape, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "170087/170087 [==============================] - 58s 342us/step - loss: 9.4726 - acc: 4.5271e-04\n",
      "Epoch 2/2000\n",
      "170087/170087 [==============================] - 58s 343us/step - loss: 9.4715 - acc: 5.4678e-04\n",
      "Epoch 3/2000\n",
      "170087/170087 [==============================] - 63s 373us/step - loss: 9.4706 - acc: 6.4085e-04\n",
      "Epoch 4/2000\n",
      "170087/170087 [==============================] - 72s 423us/step - loss: 9.4697 - acc: 6.4673e-04\n",
      "Epoch 5/2000\n",
      "170087/170087 [==============================] - 68s 398us/step - loss: 9.4689 - acc: 6.9376e-04\n",
      "Epoch 6/2000\n",
      "170087/170087 [==============================] - 67s 396us/step - loss: 9.4676 - acc: 7.2904e-04\n",
      "Epoch 7/2000\n",
      "170087/170087 [==============================] - 68s 398us/step - loss: 9.4667 - acc: 8.2899e-04\n",
      "Epoch 8/2000\n",
      "170087/170087 [==============================] - 69s 407us/step - loss: 9.4655 - acc: 9.2894e-04\n",
      "Epoch 9/2000\n",
      "170087/170087 [==============================] - 69s 407us/step - loss: 9.4648 - acc: 8.5838e-04\n",
      "Epoch 10/2000\n",
      "170087/170087 [==============================] - 67s 396us/step - loss: 9.4638 - acc: 0.0011\n",
      "Epoch 11/2000\n",
      "170087/170087 [==============================] - 67s 393us/step - loss: 9.4629 - acc: 0.0010\n",
      "Epoch 12/2000\n",
      "170087/170087 [==============================] - 67s 393us/step - loss: 9.4621 - acc: 0.0011\n",
      "Epoch 13/2000\n",
      "170087/170087 [==============================] - 67s 392us/step - loss: 9.4612 - acc: 9.9361e-04\n",
      "Epoch 14/2000\n",
      "170087/170087 [==============================] - 73s 429us/step - loss: 9.4604 - acc: 0.0012\n",
      "Epoch 15/2000\n",
      "170087/170087 [==============================] - 69s 407us/step - loss: 9.4601 - acc: 0.0011\n",
      "Epoch 16/2000\n",
      "170087/170087 [==============================] - 75s 444us/step - loss: 9.4591 - acc: 0.0012\n",
      "Epoch 17/2000\n",
      "170087/170087 [==============================] - 67s 396us/step - loss: 9.4584 - acc: 0.0012\n",
      "Epoch 18/2000\n",
      "170087/170087 [==============================] - 66s 391us/step - loss: 9.4580 - acc: 0.0012\n",
      "Epoch 19/2000\n",
      "170087/170087 [==============================] - 63s 369us/step - loss: 9.4572 - acc: 0.0013\n",
      "Epoch 20/2000\n",
      "  2176/170087 [..............................] - ETA: 56s - loss: 9.4445 - acc: 9.1912e-04"
     ]
    }
   ],
   "source": [
    "model.fit(dataset_x, dataset_y, epochs=2000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7110/7110 [==============================] - 0s 42us/step\n",
      "[9.249192657685313, 0.00829817158931083]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(dataset_x, dataset_y, batch_size=128)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "Start:  0.44285107 [25] End:  0.54137677 [91]\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(np.reshape(dataset_x[0], (1, 7, 8, 8)))\n",
    "output = output[0]\n",
    "val1 = np.amax(output[:64])\n",
    "val2 = np.amax(output[64:])\n",
    "idx1 = np.where(output == val1)[0]\n",
    "idx2 = np.where(output == val2)[0]\n",
    "\n",
    "print('Start: ', val1, idx1, 'End: ', val2, idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(input_shape)\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adadelta(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "\n",
    "# # print(x_train[0])\n",
    "# # print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
